{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "6f00e2234192f28c37a7eed5a00136f0f7305b656b202c591e67c7064728c6c1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: tensorflow==2.0.0-alpha0 in .\\venv\\lib\\site-packages (2.0.0a0)\nRequirement already satisfied: grpcio>=1.8.6 in .\\venv\\lib\\site-packages (from tensorflow==2.0.0-alpha0) (1.38.1)\nRequirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in .\\venv\\lib\\site-packages (from tensorflow==2.0.0-alpha0) (1.14.0a20190301)\nRequirement already satisfied: protobuf>=3.6.1 in .\\venv\\lib\\site-packages (from tensorflow==2.0.0-alpha0) (3.17.3)\nRequirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in .\\venv\\lib\\site-packages (from tensorflow==2.0.0-alpha0) (1.14.0.dev2019030115)\nRequirement already satisfied: astor>=0.6.0 in .\\venv\\lib\\site-packages (from tensorflow==2.0.0-alpha0) (0.8.1)\nRequirement already satisfied: absl-py>=0.7.0 in .\\venv\\lib\\site-packages (from tensorflow==2.0.0-alpha0) (0.13.0)\nRequirement already satisfied: six>=1.10.0 in .\\venv\\lib\\site-packages (from tensorflow==2.0.0-alpha0) (1.16.0)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in .\\venv\\lib\\site-packages (from tensorflow==2.0.0-alpha0) (1.1.2)\nRequirement already satisfied: keras-applications>=1.0.6 in .\\venv\\lib\\site-packages (from tensorflow==2.0.0-alpha0) (1.0.8)\nRequirement already satisfied: gast>=0.2.0 in .\\venv\\lib\\site-packages (from tensorflow==2.0.0-alpha0) (0.5.0)\nRequirement already satisfied: google-pasta>=0.1.2 in .\\venv\\lib\\site-packages (from tensorflow==2.0.0-alpha0) (0.2.0)\nRequirement already satisfied: wheel>=0.26 in .\\venv\\lib\\site-packages (from tensorflow==2.0.0-alpha0) (0.36.2)\nRequirement already satisfied: numpy<2.0,>=1.14.5 in .\\venv\\lib\\site-packages (from tensorflow==2.0.0-alpha0) (1.21.0)\nRequirement already satisfied: termcolor>=1.1.0 in .\\venv\\lib\\site-packages (from tensorflow==2.0.0-alpha0) (1.1.0)\nRequirement already satisfied: h5py in .\\venv\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-alpha0) (3.3.0)\nRequirement already satisfied: werkzeug>=0.11.15 in .\\venv\\lib\\site-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (2.0.1)\nRequirement already satisfied: markdown>=2.6.8 in .\\venv\\lib\\site-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (3.3.4)\nRequirement already satisfied: importlib-metadata in .\\venv\\lib\\site-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (3.10.1)\nRequirement already satisfied: cached-property in .\\venv\\lib\\site-packages (from h5py->keras-applications>=1.0.6->tensorflow==2.0.0-alpha0) (1.5.2)\nRequirement already satisfied: zipp>=0.5 in .\\venv\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (3.5.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in .\\venv\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (3.10.0.0)\nNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==2.0.0-alpha0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "d:\\workspace\\course_google_tensorflow\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\workspace\\course_google_tensorflow\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\workspace\\course_google_tensorflow\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\workspace\\course_google_tensorflow\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\workspace\\course_google_tensorflow\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\workspace\\course_google_tensorflow\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "d:\\workspace\\course_google_tensorflow\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\workspace\\course_google_tensorflow\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\workspace\\course_google_tensorflow\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\workspace\\course_google_tensorflow\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\workspace\\course_google_tensorflow\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\workspace\\course_google_tensorflow\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1,input_shape=[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array([-1.0,0.0,1.0,2.0,3.0,4.0], dtype=float)\n",
    "ys = np.array([-3.0,-1.0,1.0,3.0,5.0,7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=========] - 0s 167us/sample - loss: 0.0275\n",
      "Epoch 1767/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0275\n",
      "Epoch 1768/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0274\n",
      "Epoch 1769/2000\n",
      "6/6 [==============================] - 0s 166us/sample - loss: 0.0274\n",
      "Epoch 1770/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0273\n",
      "Epoch 1771/2000\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 0.0273\n",
      "Epoch 1772/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0272\n",
      "Epoch 1773/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0271\n",
      "Epoch 1774/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0271\n",
      "Epoch 1775/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0270\n",
      "Epoch 1776/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0270\n",
      "Epoch 1777/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0269\n",
      "Epoch 1778/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0269\n",
      "Epoch 1779/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0268\n",
      "Epoch 1780/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0268\n",
      "Epoch 1781/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0267\n",
      "Epoch 1782/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0266\n",
      "Epoch 1783/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0266\n",
      "Epoch 1784/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0265\n",
      "Epoch 1785/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0265\n",
      "Epoch 1786/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0264\n",
      "Epoch 1787/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0264\n",
      "Epoch 1788/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0263\n",
      "Epoch 1789/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0263\n",
      "Epoch 1790/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0262\n",
      "Epoch 1791/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0262\n",
      "Epoch 1792/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0261\n",
      "Epoch 1793/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0260\n",
      "Epoch 1794/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0260\n",
      "Epoch 1795/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0259\n",
      "Epoch 1796/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0259\n",
      "Epoch 1797/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0258\n",
      "Epoch 1798/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0258\n",
      "Epoch 1799/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0257\n",
      "Epoch 1800/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0257\n",
      "Epoch 1801/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0256\n",
      "Epoch 1802/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0256\n",
      "Epoch 1803/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0255\n",
      "Epoch 1804/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0255\n",
      "Epoch 1805/2000\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0254\n",
      "Epoch 1806/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0254\n",
      "Epoch 1807/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0253\n",
      "Epoch 1808/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0252\n",
      "Epoch 1809/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0252\n",
      "Epoch 1810/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0251\n",
      "Epoch 1811/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0251\n",
      "Epoch 1812/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0250\n",
      "Epoch 1813/2000\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 0.0250\n",
      "Epoch 1814/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0249\n",
      "Epoch 1815/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0249\n",
      "Epoch 1816/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0248\n",
      "Epoch 1817/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0248\n",
      "Epoch 1818/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0247\n",
      "Epoch 1819/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0247\n",
      "Epoch 1820/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0246\n",
      "Epoch 1821/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0246\n",
      "Epoch 1822/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0245\n",
      "Epoch 1823/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0245\n",
      "Epoch 1824/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0244\n",
      "Epoch 1825/2000\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 0.0244\n",
      "Epoch 1826/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0243\n",
      "Epoch 1827/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0243\n",
      "Epoch 1828/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0242\n",
      "Epoch 1829/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0242\n",
      "Epoch 1830/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0241\n",
      "Epoch 1831/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0241\n",
      "Epoch 1832/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0240\n",
      "Epoch 1833/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0240\n",
      "Epoch 1834/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0239\n",
      "Epoch 1835/2000\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 0.0239\n",
      "Epoch 1836/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0238\n",
      "Epoch 1837/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0238\n",
      "Epoch 1838/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0237\n",
      "Epoch 1839/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0237\n",
      "Epoch 1840/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0236\n",
      "Epoch 1841/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0236\n",
      "Epoch 1842/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0235\n",
      "Epoch 1843/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0235\n",
      "Epoch 1844/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0234\n",
      "Epoch 1845/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0234\n",
      "Epoch 1846/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0233\n",
      "Epoch 1847/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0233\n",
      "Epoch 1848/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0232\n",
      "Epoch 1849/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0232\n",
      "Epoch 1850/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0232\n",
      "Epoch 1851/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0231\n",
      "Epoch 1852/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0231\n",
      "Epoch 1853/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0230\n",
      "Epoch 1854/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0230\n",
      "Epoch 1855/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0229\n",
      "Epoch 1856/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0229\n",
      "Epoch 1857/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0228\n",
      "Epoch 1858/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0228\n",
      "Epoch 1859/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0227\n",
      "Epoch 1860/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0227\n",
      "Epoch 1861/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0226\n",
      "Epoch 1862/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0226\n",
      "Epoch 1863/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0225\n",
      "Epoch 1864/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0225\n",
      "Epoch 1865/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0224\n",
      "Epoch 1866/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0224\n",
      "Epoch 1867/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0224\n",
      "Epoch 1868/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0223\n",
      "Epoch 1869/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0223\n",
      "Epoch 1870/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0222\n",
      "Epoch 1871/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0222\n",
      "Epoch 1872/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0221\n",
      "Epoch 1873/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0221\n",
      "Epoch 1874/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0220\n",
      "Epoch 1875/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0220\n",
      "Epoch 1876/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0219\n",
      "Epoch 1877/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0219\n",
      "Epoch 1878/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0219\n",
      "Epoch 1879/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0218\n",
      "Epoch 1880/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0218\n",
      "Epoch 1881/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0217\n",
      "Epoch 1882/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0217\n",
      "Epoch 1883/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0216\n",
      "Epoch 1884/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0216\n",
      "Epoch 1885/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0215\n",
      "Epoch 1886/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0215\n",
      "Epoch 1887/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0214\n",
      "Epoch 1888/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0214\n",
      "Epoch 1889/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0214\n",
      "Epoch 1890/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0213\n",
      "Epoch 1891/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0213\n",
      "Epoch 1892/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0212\n",
      "Epoch 1893/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0212\n",
      "Epoch 1894/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0211\n",
      "Epoch 1895/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0211\n",
      "Epoch 1896/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0211\n",
      "Epoch 1897/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0210\n",
      "Epoch 1898/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0210\n",
      "Epoch 1899/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0209\n",
      "Epoch 1900/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0209\n",
      "Epoch 1901/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0208\n",
      "Epoch 1902/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0208\n",
      "Epoch 1903/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0208\n",
      "Epoch 1904/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0207\n",
      "Epoch 1905/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0207\n",
      "Epoch 1906/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0206\n",
      "Epoch 1907/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0206\n",
      "Epoch 1908/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0205\n",
      "Epoch 1909/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0205\n",
      "Epoch 1910/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0205\n",
      "Epoch 1911/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0204\n",
      "Epoch 1912/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0204\n",
      "Epoch 1913/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0203\n",
      "Epoch 1914/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0203\n",
      "Epoch 1915/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0202\n",
      "Epoch 1916/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0202\n",
      "Epoch 1917/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0202\n",
      "Epoch 1918/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0201\n",
      "Epoch 1919/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0201\n",
      "Epoch 1920/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0200\n",
      "Epoch 1921/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0200\n",
      "Epoch 1922/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0200\n",
      "Epoch 1923/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0199\n",
      "Epoch 1924/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0199\n",
      "Epoch 1925/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0198\n",
      "Epoch 1926/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0198\n",
      "Epoch 1927/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0197\n",
      "Epoch 1928/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0197\n",
      "Epoch 1929/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0197\n",
      "Epoch 1930/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0196\n",
      "Epoch 1931/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0196\n",
      "Epoch 1932/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0195\n",
      "Epoch 1933/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0195\n",
      "Epoch 1934/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0195\n",
      "Epoch 1935/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0194\n",
      "Epoch 1936/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0194\n",
      "Epoch 1937/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0193\n",
      "Epoch 1938/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0193\n",
      "Epoch 1939/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0193\n",
      "Epoch 1940/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0192\n",
      "Epoch 1941/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0192\n",
      "Epoch 1942/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0191\n",
      "Epoch 1943/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0191\n",
      "Epoch 1944/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0191\n",
      "Epoch 1945/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0190\n",
      "Epoch 1946/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0190\n",
      "Epoch 1947/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0189\n",
      "Epoch 1948/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0189\n",
      "Epoch 1949/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0189\n",
      "Epoch 1950/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0188\n",
      "Epoch 1951/2000\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0188\n",
      "Epoch 1952/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0188\n",
      "Epoch 1953/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0187\n",
      "Epoch 1954/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0187\n",
      "Epoch 1955/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0186\n",
      "Epoch 1956/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0186\n",
      "Epoch 1957/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0186\n",
      "Epoch 1958/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0185\n",
      "Epoch 1959/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0185\n",
      "Epoch 1960/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0184\n",
      "Epoch 1961/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0184\n",
      "Epoch 1962/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0184\n",
      "Epoch 1963/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0183\n",
      "Epoch 1964/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0183\n",
      "Epoch 1965/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0183\n",
      "Epoch 1966/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0182\n",
      "Epoch 1967/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0182\n",
      "Epoch 1968/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0181\n",
      "Epoch 1969/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0181\n",
      "Epoch 1970/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0181\n",
      "Epoch 1971/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0180\n",
      "Epoch 1972/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0180\n",
      "Epoch 1973/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0180\n",
      "Epoch 1974/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0179\n",
      "Epoch 1975/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0179\n",
      "Epoch 1976/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0178\n",
      "Epoch 1977/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0178\n",
      "Epoch 1978/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0178\n",
      "Epoch 1979/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0177\n",
      "Epoch 1980/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0177\n",
      "Epoch 1981/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0177\n",
      "Epoch 1982/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0176\n",
      "Epoch 1983/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0176\n",
      "Epoch 1984/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0176\n",
      "Epoch 1985/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0175\n",
      "Epoch 1986/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0175\n",
      "Epoch 1987/2000\n",
      "6/6 [==============================] - 0s 161us/sample - loss: 0.0174\n",
      "Epoch 1988/2000\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0174\n",
      "Epoch 1989/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0174\n",
      "Epoch 1990/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0173\n",
      "Epoch 1991/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0173\n",
      "Epoch 1992/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0173\n",
      "Epoch 1993/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0172\n",
      "Epoch 1994/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0172\n",
      "Epoch 1995/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0172\n",
      "Epoch 1996/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0171\n",
      "Epoch 1997/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0171\n",
      "Epoch 1998/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0171\n",
      "Epoch 1999/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0170\n",
      "Epoch 2000/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0170\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x214df2302c8>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "model.fit(xs,ys, epochs=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[18.616219]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([10.0]))"
   ]
  },
  {
   "source": [
    "### Week1 Quiz\n",
    "\n",
    "1. The diagram for traditional programming had Rules and Data in, but what came out?  \n",
    "- [ ] Binary  \n",
    "- [ ] Machine Learning  \n",
    "- [ ] Bugs  \n",
    "- [X] Answers  \n",
    "\n",
    "2. The diagram for Machine Learning had Answers and Data In, but what came out?  \n",
    "- [ ] Bugs  \n",
    "- [ ] Binary  \n",
    "- [X] Rules  \n",
    "- [ ] Models  \n",
    "\n",
    "3. When I tell a computer what the data represents(i.e. this data is for walking, this data is for running), what is that process called?  \n",
    "- [ ] Categorizing the Data  \n",
    "- [ ] Programming the Data  \n",
    "- [ ] Learning the Data  \n",
    "- [X] Labelling the Data  \n",
    "\n",
    "4. What is a Dense?  \n",
    "- [X] A layer of connected neurons  \n",
    "- [ ] A single neurons  \n",
    "- [ ] A layer of disconnected neurons  \n",
    "- [ ] Mass over Volume  \n",
    "\n",
    "5. What does a Loss function do?  \n",
    "- [ ] Figures out if you win or lose  \n",
    "- [X] Measures how good the current 'guess' is  \n",
    "- [ ] Generates a guess  \n",
    "- [ ] Decides to stop training a neural network  \n",
    "\n",
    "6. What does the optimizer do?  \n",
    "- [ ] Decides to stop training a neural network  \n",
    "- [ ] Measures how good the current guess is  \n",
    "- [ ] Figures out how to efficiently complie your code  \n",
    "- [X] Generates a new and Improved guess  \n",
    "\n",
    "7. What is Convergence?  \n",
    "- [ ] A Dramatic increase in Loss  \n",
    "- [ ] The bad guys in the next 'Star Wars' movie  \n",
    "- [X] The process of getting very close to the correct Answers  \n",
    "- [ ] A programming API for AI  \n",
    "\n",
    "8. What does model.fit do?  \n",
    "- [ ] It makes a model fit avaliable memory  \n",
    "- [ ] It optimizes an exiting model  \n",
    "- [X] It trains the neural network to fit noe set fo values th another  \n",
    "- [ ] It determines if your activity is good for your body"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==============================] - 0s 0s/sample - loss: 0.0210\n",
      "Epoch 1768/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0209\n",
      "Epoch 1769/2000\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 0.0209\n",
      "Epoch 1770/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0209\n",
      "Epoch 1771/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0209\n",
      "Epoch 1772/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0208\n",
      "Epoch 1773/2000\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 0.0208\n",
      "Epoch 1774/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0208\n",
      "Epoch 1775/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0208\n",
      "Epoch 1776/2000\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 0.0207\n",
      "Epoch 1777/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0207\n",
      "Epoch 1778/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0207\n",
      "Epoch 1779/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0207\n",
      "Epoch 1780/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0206\n",
      "Epoch 1781/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0206\n",
      "Epoch 1782/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0206\n",
      "Epoch 1783/2000\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 0.0205\n",
      "Epoch 1784/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0205\n",
      "Epoch 1785/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0205\n",
      "Epoch 1786/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0205\n",
      "Epoch 1787/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0204\n",
      "Epoch 1788/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0204\n",
      "Epoch 1789/2000\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 0.0204\n",
      "Epoch 1790/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0204\n",
      "Epoch 1791/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0203\n",
      "Epoch 1792/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0203\n",
      "Epoch 1793/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0203\n",
      "Epoch 1794/2000\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 0.0203\n",
      "Epoch 1795/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0202\n",
      "Epoch 1796/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0202\n",
      "Epoch 1797/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0202\n",
      "Epoch 1798/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0202\n",
      "Epoch 1799/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0201\n",
      "Epoch 1800/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0201\n",
      "Epoch 1801/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0201\n",
      "Epoch 1802/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0201\n",
      "Epoch 1803/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0200\n",
      "Epoch 1804/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0200\n",
      "Epoch 1805/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0200\n",
      "Epoch 1806/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0200\n",
      "Epoch 1807/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0199\n",
      "Epoch 1808/2000\n",
      "6/6 [==============================] - 0s 168us/sample - loss: 0.0199\n",
      "Epoch 1809/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0199\n",
      "Epoch 1810/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0199\n",
      "Epoch 1811/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0198\n",
      "Epoch 1812/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0198\n",
      "Epoch 1813/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0198\n",
      "Epoch 1814/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0198\n",
      "Epoch 1815/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0197\n",
      "Epoch 1816/2000\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 0.0197\n",
      "Epoch 1817/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0197\n",
      "Epoch 1818/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0197\n",
      "Epoch 1819/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0196\n",
      "Epoch 1820/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0196\n",
      "Epoch 1821/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0196\n",
      "Epoch 1822/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0196\n",
      "Epoch 1823/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0195\n",
      "Epoch 1824/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0195\n",
      "Epoch 1825/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0195\n",
      "Epoch 1826/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0195\n",
      "Epoch 1827/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0194\n",
      "Epoch 1828/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0194\n",
      "Epoch 1829/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0194\n",
      "Epoch 1830/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0194\n",
      "Epoch 1831/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0194\n",
      "Epoch 1832/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0193\n",
      "Epoch 1833/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0193\n",
      "Epoch 1834/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0193\n",
      "Epoch 1835/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0193\n",
      "Epoch 1836/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0192\n",
      "Epoch 1837/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0192\n",
      "Epoch 1838/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0192\n",
      "Epoch 1839/2000\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 0.0192\n",
      "Epoch 1840/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0191\n",
      "Epoch 1841/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0191\n",
      "Epoch 1842/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0191\n",
      "Epoch 1843/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0191\n",
      "Epoch 1844/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0190\n",
      "Epoch 1845/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0190\n",
      "Epoch 1846/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0190\n",
      "Epoch 1847/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0190\n",
      "Epoch 1848/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0189\n",
      "Epoch 1849/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0189\n",
      "Epoch 1850/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0189\n",
      "Epoch 1851/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0189\n",
      "Epoch 1852/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0189\n",
      "Epoch 1853/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0188\n",
      "Epoch 1854/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0188\n",
      "Epoch 1855/2000\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 0.0188\n",
      "Epoch 1856/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0188\n",
      "Epoch 1857/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0187\n",
      "Epoch 1858/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0187\n",
      "Epoch 1859/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0187\n",
      "Epoch 1860/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0187\n",
      "Epoch 1861/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0186\n",
      "Epoch 1862/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0186\n",
      "Epoch 1863/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0186\n",
      "Epoch 1864/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0186\n",
      "Epoch 1865/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0185\n",
      "Epoch 1866/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0185\n",
      "Epoch 1867/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0185\n",
      "Epoch 1868/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0185\n",
      "Epoch 1869/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0185\n",
      "Epoch 1870/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0184\n",
      "Epoch 1871/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0184\n",
      "Epoch 1872/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0184\n",
      "Epoch 1873/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0184\n",
      "Epoch 1874/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0183\n",
      "Epoch 1875/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0183\n",
      "Epoch 1876/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0183\n",
      "Epoch 1877/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0183\n",
      "Epoch 1878/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0182\n",
      "Epoch 1879/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0182\n",
      "Epoch 1880/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0182\n",
      "Epoch 1881/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0182\n",
      "Epoch 1882/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0182\n",
      "Epoch 1883/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0181\n",
      "Epoch 1884/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0181\n",
      "Epoch 1885/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0181\n",
      "Epoch 1886/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0181\n",
      "Epoch 1887/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0180\n",
      "Epoch 1888/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0180\n",
      "Epoch 1889/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0180\n",
      "Epoch 1890/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0180\n",
      "Epoch 1891/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0180\n",
      "Epoch 1892/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0179\n",
      "Epoch 1893/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0179\n",
      "Epoch 1894/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0179\n",
      "Epoch 1895/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0179\n",
      "Epoch 1896/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0178\n",
      "Epoch 1897/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0178\n",
      "Epoch 1898/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0178\n",
      "Epoch 1899/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0178\n",
      "Epoch 1900/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0178\n",
      "Epoch 1901/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0177\n",
      "Epoch 1902/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0177\n",
      "Epoch 1903/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0177\n",
      "Epoch 1904/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0177\n",
      "Epoch 1905/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0176\n",
      "Epoch 1906/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0176\n",
      "Epoch 1907/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0176\n",
      "Epoch 1908/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0176\n",
      "Epoch 1909/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0176\n",
      "Epoch 1910/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0175\n",
      "Epoch 1911/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0175\n",
      "Epoch 1912/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0175\n",
      "Epoch 1913/2000\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 0.0175\n",
      "Epoch 1914/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0174\n",
      "Epoch 1915/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0174\n",
      "Epoch 1916/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0174\n",
      "Epoch 1917/2000\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 0.0174\n",
      "Epoch 1918/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0174\n",
      "Epoch 1919/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0173\n",
      "Epoch 1920/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0173\n",
      "Epoch 1921/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0173\n",
      "Epoch 1922/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0173\n",
      "Epoch 1923/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0172\n",
      "Epoch 1924/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0172\n",
      "Epoch 1925/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0172\n",
      "Epoch 1926/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0172\n",
      "Epoch 1927/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0172\n",
      "Epoch 1928/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0171\n",
      "Epoch 1929/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0171\n",
      "Epoch 1930/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0171\n",
      "Epoch 1931/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0171\n",
      "Epoch 1932/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0171\n",
      "Epoch 1933/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0170\n",
      "Epoch 1934/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0170\n",
      "Epoch 1935/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0170\n",
      "Epoch 1936/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0170\n",
      "Epoch 1937/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0170\n",
      "Epoch 1938/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0169\n",
      "Epoch 1939/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0169\n",
      "Epoch 1940/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0169\n",
      "Epoch 1941/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0169\n",
      "Epoch 1942/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0168\n",
      "Epoch 1943/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0168\n",
      "Epoch 1944/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0168\n",
      "Epoch 1945/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0168\n",
      "Epoch 1946/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0168\n",
      "Epoch 1947/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0167\n",
      "Epoch 1948/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0167\n",
      "Epoch 1949/2000\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 0.0167\n",
      "Epoch 1950/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0167\n",
      "Epoch 1951/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0167\n",
      "Epoch 1952/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0166\n",
      "Epoch 1953/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0166\n",
      "Epoch 1954/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0166\n",
      "Epoch 1955/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0166\n",
      "Epoch 1956/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0166\n",
      "Epoch 1957/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0165\n",
      "Epoch 1958/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0165\n",
      "Epoch 1959/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0165\n",
      "Epoch 1960/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0165\n",
      "Epoch 1961/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0164\n",
      "Epoch 1962/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0164\n",
      "Epoch 1963/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0164\n",
      "Epoch 1964/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0164\n",
      "Epoch 1965/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0164\n",
      "Epoch 1966/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0163\n",
      "Epoch 1967/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0163\n",
      "Epoch 1968/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0163\n",
      "Epoch 1969/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0163\n",
      "Epoch 1970/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0163\n",
      "Epoch 1971/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0162\n",
      "Epoch 1972/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0162\n",
      "Epoch 1973/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0162\n",
      "Epoch 1974/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0162\n",
      "Epoch 1975/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0162\n",
      "Epoch 1976/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0161\n",
      "Epoch 1977/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0161\n",
      "Epoch 1978/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0161\n",
      "Epoch 1979/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0161\n",
      "Epoch 1980/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0161\n",
      "Epoch 1981/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0160\n",
      "Epoch 1982/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0160\n",
      "Epoch 1983/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0160\n",
      "Epoch 1984/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0160\n",
      "Epoch 1985/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0160\n",
      "Epoch 1986/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0159\n",
      "Epoch 1987/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0159\n",
      "Epoch 1988/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0159\n",
      "Epoch 1989/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0159\n",
      "Epoch 1990/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0159\n",
      "Epoch 1991/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0158\n",
      "Epoch 1992/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0158\n",
      "Epoch 1993/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0158\n",
      "Epoch 1994/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0158\n",
      "Epoch 1995/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0158\n",
      "Epoch 1996/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0157\n",
      "Epoch 1997/2000\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0157\n",
      "Epoch 1998/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0157\n",
      "Epoch 1999/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0157\n",
      "Epoch 2000/2000\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 0.0157\n",
      "[[103.82804]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras \n",
    "\n",
    "model = tf.keras.Sequential([keras.layers.Dense(units=1,input_shape=[1])])\n",
    "\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "xs = np.array([0,2,4,6,8,10], dtype=float)\n",
    "ys = np.array([1,3,5,7,9,11], dtype=float)\n",
    "\n",
    "model.fit(xs,ys, epochs=2000)\n",
    "\n",
    "print(model.predict([100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Exercise_1_House_Prices_Question\n",
    "## \n",
    "'''\n",
    "In this exercise you'll try to build a neural network that predicts the price of a house according to a simple formula.\n",
    "\n",
    "So, imagine if house pricing was as easy as a house costs 50k + 50k per bedroom, so that a 1 bedroom house costs 100k, a 2 bedroom house costs 150k etc.\n",
    "\n",
    "How would you create a neural network that learns this relationship so that it would predict a 7 bedroom house as costing close to 400k etc.\n",
    "\n",
    "Hint: Your network might work better if you scale the house price down. You don't have to give the answer 400...it might be better to create something that predicts the number 4, and then your answer is in the 'hundreds of thousands' etc.\n",
    "'''\n",
    "\n",
    "'''\n",
    "  : 0.1\n",
    "  \n",
    " 7 x \n",
    "'''\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "from tensorflow import keras \n",
    "\n",
    "def house_model(y_new):\n",
    "    xs = [x for x in range(6)]\n",
    "    ys = [1+(x-1)*0.5 for x in range(6)]\n",
    "    model = tf.keras.Sequential([keras.layers.Dense(units=1,input_shape=[1])])\n",
    "    model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "    model.fit(xs,ys, epochs=4000)\n",
    "    return model.predict(y_new)[0]\n",
    "\n",
    "prediction = house_model([7.0])\n",
    "print(prediction)"
   ]
  }
 ]
}